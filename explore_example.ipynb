{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Extracted Logits\n",
    "\n",
    "This notebook demonstrates how to explore and visualize extracted logit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all exploration functions\n",
    "from explore_logits import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your dataset ID\n",
    "DATASET_ID = \"seba/devLogits-Q3-0.6B\"\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_logit_dataset(DATASET_ID)\n",
    "print(f\"Dataset has {len(ds)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore a Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample\n",
    "sample = get_sample(ds, index=0)\n",
    "\n",
    "# Print information about the sample\n",
    "print_sample_info(sample, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Nucleus Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how nucleus size varies across tokens\n",
    "plot_nucleus_sizes(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect a Specific Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a token to inspect\n",
    "TOKEN_IDX = 0\n",
    "\n",
    "# Plot logit distribution for this token\n",
    "plot_logit_distribution(sample, token_idx=TOKEN_IDX, show_top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare nucleus vs sampled distributions\n",
    "plot_nucleus_vs_sampled(sample, token_idx=TOKEN_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dequantize and Inspect Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dequantize nucleus logits\n",
    "nucleus_indices, nucleus_logits = dequantize_top_logits(sample, token_idx=TOKEN_IDX)\n",
    "\n",
    "print(f\"Nucleus has {len(nucleus_indices)} tokens\")\n",
    "print(f\"Top 5 logit values: {nucleus_logits[:5]}\")\n",
    "print(f\"Top 5 token indices: {nucleus_indices[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dequantize sampled logits\n",
    "sampled_indices, sampled_logits = dequantize_sampled_logits(sample, token_idx=TOKEN_IDX)\n",
    "\n",
    "print(f\"Sampled has {len(sampled_indices)} tokens\")\n",
    "print(f\"Sampled logit range: [{sampled_logits.min():.3f}, {sampled_logits.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all logits at once\n",
    "logits_dict = dequantize_all_logits(sample, token_idx=TOKEN_IDX)\n",
    "\n",
    "print(\"Keys in logits_dict:\", logits_dict.keys())\n",
    "print(f\"LogSumExp: {logits_dict['logsumexp']:.3f}\")\n",
    "\n",
    "# Check nucleus probability mass\n",
    "nucleus_mass = get_nucleus_probability_mass(sample, token_idx=TOKEN_IDX)\n",
    "print(f\"\\nNucleus captures {nucleus_mass*100:.2f}% of probability mass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Decode Tokens (Optional - requires model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer to decode token IDs to strings\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Replace with the model you used for extraction\n",
    "MODEL_ID = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top tokens with their probabilities\n",
    "print_top_tokens(sample, token_idx=TOKEN_IDX, tokenizer=tokenizer, top_k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compute Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute stats across the dataset (may take a while for large datasets)\n",
    "stats = compute_dataset_stats(ds, max_samples=1000)  # Limit to first 1000 samples\n",
    "\n",
    "# Print statistics\n",
    "print_dataset_stats(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quick Exploration (All-in-One)\n",
    "\n",
    "For quick analysis, use the `quick_explore` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick exploration with all visualizations\n",
    "quick_explore(\n",
    "    dataset_id=DATASET_ID,\n",
    "    sample_idx=0,\n",
    "    token_idx=0,\n",
    "    model_id=MODEL_ID  # Optional, for token decoding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Custom Analysis\n",
    "\n",
    "Example: Compare logit distributions across multiple tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare top token probabilities across positions\n",
    "token_positions = range(min(10, sample['num_tokens']))\n",
    "top_probs = []\n",
    "\n",
    "for token_idx in token_positions:\n",
    "    indices, logits = dequantize_top_logits(sample, token_idx)\n",
    "    lse = sample['logsumexp'][token_idx]\n",
    "    probs = logits_to_probs(logits, lse)\n",
    "    top_probs.append(probs[0])  # Probability of top token\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(token_positions, top_probs, marker='o', linewidth=2)\n",
    "plt.xlabel('Token Position')\n",
    "plt.ylabel('Top Token Probability')\n",
    "plt.title('Confidence (Top Token Probability) Across Sequence')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average top token probability: {np.mean(top_probs):.3f}\")\n",
    "print(f\"Min: {min(top_probs):.3f}, Max: {max(top_probs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Data for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Export top-5 tokens for each position to CSV\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "for token_idx in range(sample['num_tokens']):\n",
    "    indices, logits = dequantize_top_logits(sample, token_idx)\n",
    "    lse = sample['logsumexp'][token_idx]\n",
    "    probs = logits_to_probs(logits, lse)\n",
    "    \n",
    "    for rank in range(min(5, len(indices))):\n",
    "        data.append({\n",
    "            'token_position': token_idx,\n",
    "            'rank': rank + 1,\n",
    "            'token_id': indices[rank],\n",
    "            'logit': logits[rank],\n",
    "            'probability': probs[rank]\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head(10))\n",
    "\n",
    "# Optionally save to CSV\n",
    "# df.to_csv('top_tokens.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
